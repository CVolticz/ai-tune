{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd738d4",
   "metadata": {},
   "source": [
    "# Music Theory:\n",
    "\n",
    "## Terminology:\n",
    "\n",
    "* Pitch: refers to the frequency of the sound, or how high or low it is and is represented with the letters [A, B, C, D, E, F, G], with A being the highest and G being the lowest.\n",
    "* Octave: refers to which set of pitches you use on a piano.\n",
    "* Offset: refers to where the note is located in the piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d58045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from music21 import converter, instrument, note, chord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65bca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88af4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4cde624d5f4726ae17b747d3a8171f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in music and prepare it in a list of notes\n",
    "notes = []\n",
    "for file in tqdm(glob.glob(\"../data/midi_songs/*.mid\")):\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    # Two cases:\n",
    "    # 1. music file has instrument parts\n",
    "    # 2. music file has notes in a flat structure\n",
    "    try: # file has instrument parts\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse() \n",
    "    except: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        \n",
    "    # each note elements exported and append to an array of notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adefe1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45872, 100, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre-processing:\n",
    "# 1. get all pitch name\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "# 2. create a dictionary to map pitches to integers (essentially OHE the pitches)\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "# 3. Creating a input/output sequences for the neural network\n",
    "# The output for each sequence of length 100 is the first note or chord that come after the sequence of notes\n",
    "sequence_length = 100\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    \n",
    "    # map the input/output string(s) to a numerical value for training purposes\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "\n",
    "# determine the number of different pattern generated\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "# essentially, the array of array is to be reshape by(x_pattern, y_length, )\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "# Post processing on input/outputs\n",
    "# normalize input\n",
    "# OHE the output -> so that softmax can be use to generate a probability\n",
    "network_input = network_input / float(len(pitchnames))\n",
    "network_output = tf.keras.utils.to_categorical(network_output)\n",
    "network_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1befd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Designing the Neural network:\n",
    "\n",
    "# Start a new session before training/clear out everything prior\n",
    "# This is not strictly necessary, but each time you build a model, TF adds\n",
    "# new nodes (rather than overwriting), so the colab session can end up\n",
    "# storing lots of copies of the graph when you only care about the most\n",
    "# recent. Also, as there is some randomness built into training with SGD,\n",
    "# setting a random seed ensures that results are the same on each identical\n",
    "# training run.\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Build a model using keras.Sequential.\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Input a row of data into an LSTM layer\n",
    "model.add(keras.layers.LSTM(\n",
    "    512, \n",
    "    input_shape=(network_input.shape[1], network_input.shape[2]), \n",
    "    recurrent_dropout=0.3,\n",
    "    return_sequences=True))\n",
    "\n",
    "\n",
    "model.add(keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "model.add(keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "model.add(keras.layers.LSTM(512))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# dropout ~30% of the first LSTM layer as a regularization technique\n",
    "# Useful to prevent overfitting\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# Add some hidden layers/ one more level of dropout layers\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# output layer with softmax activation on all the \n",
    "model.add(keras.layers.Dense(\n",
    "    units = len(pitchnames),\n",
    "    activation = \"softmax\"\n",
    "))\n",
    "          \n",
    "# compile the model \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('../data/trainig_outputs/weights-improvement-53-0.7322-bigger.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51a865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "359/359 [==============================] - 1090s 3s/step - loss: 0.7239 - accuracy: 0.7797\n",
      "Epoch 2/200\n",
      "359/359 [==============================] - 979s 3s/step - loss: 0.7021 - accuracy: 0.7848\n",
      "Epoch 3/200\n",
      "359/359 [==============================] - 1017s 3s/step - loss: 0.6674 - accuracy: 0.7968\n",
      "Epoch 4/200\n",
      "359/359 [==============================] - 1074s 3s/step - loss: 0.6368 - accuracy: 0.8037\n",
      "Epoch 5/200\n",
      "359/359 [==============================] - 1024s 3s/step - loss: 0.6308 - accuracy: 0.8069\n",
      "Epoch 6/200\n",
      "359/359 [==============================] - 1001s 3s/step - loss: 0.6229 - accuracy: 0.8108\n",
      "Epoch 7/200\n",
      "359/359 [==============================] - 1040s 3s/step - loss: 0.5860 - accuracy: 0.8191\n",
      "Epoch 8/200\n",
      "359/359 [==============================] - 1030s 3s/step - loss: 0.5701 - accuracy: 0.8244\n",
      "Epoch 9/200\n",
      "359/359 [==============================] - 1027s 3s/step - loss: 0.5615 - accuracy: 0.8276\n",
      "Epoch 10/200\n",
      "359/359 [==============================] - 1030s 3s/step - loss: 0.5534 - accuracy: 0.8310\n",
      "Epoch 11/200\n",
      "359/359 [==============================] - 1049s 3s/step - loss: 0.5296 - accuracy: 0.8356\n",
      "Epoch 12/200\n",
      "359/359 [==============================] - 1091s 3s/step - loss: 0.5278 - accuracy: 0.8360\n",
      "Epoch 13/200\n",
      "359/359 [==============================] - 1022s 3s/step - loss: 0.4995 - accuracy: 0.8453\n",
      "Epoch 14/200\n",
      "359/359 [==============================] - 1015s 3s/step - loss: 0.4854 - accuracy: 0.8474\n",
      "Epoch 15/200\n",
      "359/359 [==============================] - 1017s 3s/step - loss: 0.4784 - accuracy: 0.8515\n",
      "Epoch 16/200\n",
      "359/359 [==============================] - 1060s 3s/step - loss: 0.4734 - accuracy: 0.8531\n",
      "Epoch 17/200\n",
      "359/359 [==============================] - 1089s 3s/step - loss: 0.4507 - accuracy: 0.8590\n",
      "Epoch 18/200\n",
      "359/359 [==============================] - 1125s 3s/step - loss: 0.4455 - accuracy: 0.8614\n",
      "Epoch 19/200\n",
      "359/359 [==============================] - 1084s 3s/step - loss: 0.4357 - accuracy: 0.8624\n",
      "Epoch 20/200\n",
      "359/359 [==============================] - 1072s 3s/step - loss: 0.4261 - accuracy: 0.8671\n",
      "Epoch 21/200\n",
      "359/359 [==============================] - 1104s 3s/step - loss: 0.4083 - accuracy: 0.8721\n",
      "Epoch 22/200\n",
      "359/359 [==============================] - 1065s 3s/step - loss: 0.4058 - accuracy: 0.8733\n",
      "Epoch 23/200\n",
      "359/359 [==============================] - 1019s 3s/step - loss: 0.3880 - accuracy: 0.8787\n",
      "Epoch 24/200\n",
      "359/359 [==============================] - 1018s 3s/step - loss: 0.3876 - accuracy: 0.8789\n",
      "Epoch 25/200\n",
      "359/359 [==============================] - 1017s 3s/step - loss: 0.3709 - accuracy: 0.8841\n",
      "Epoch 26/200\n",
      "359/359 [==============================] - 1014s 3s/step - loss: 0.3781 - accuracy: 0.8816\n",
      "Epoch 27/200\n",
      "359/359 [==============================] - 1018s 3s/step - loss: 0.3551 - accuracy: 0.8884\n",
      "Epoch 28/200\n",
      "359/359 [==============================] - 1008s 3s/step - loss: 0.3563 - accuracy: 0.8884\n",
      "Epoch 29/200\n",
      "359/359 [==============================] - 1013s 3s/step - loss: 0.3553 - accuracy: 0.8888\n",
      "Epoch 30/200\n",
      "359/359 [==============================] - 1064s 3s/step - loss: 0.3417 - accuracy: 0.8904\n",
      "Epoch 31/200\n",
      "  4/359 [..............................] - ETA: 17:13 - loss: 0.3032 - accuracy: 0.9199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\UNIXSpace\\Git_Desktop\\Ai-Tune\\ai_tune\\notebooks\\ai_tune_builder.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     filepath, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,        \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,        \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )    \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m callbacks_list \u001b[39m=\u001b[39m [checkpoint]     \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Ai-Tune/ai_tune/notebooks/ai_tune_builder.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(network_input, network_output, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mcallbacks_list)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ktrin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "filepath = \"../data/trainig_outputs/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df7b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169343c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8c224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9845b488047c880b3243e38cff204b64842e109bc52f8ea3e8abc45a8d12589d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
